{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ragha\\Desktop\\Projects\\Image-Captioning\n"
     ]
    }
   ],
   "source": [
    "!pip install discord --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!git clone https://{Github Username}:{Password}@github.com/RaghavPrabhakar66/Image-Captioning.git\n",
    "!gdown 'https://drive.google.com/uc?id=1P1OrXzqNklAqC_Mmm8h9NcwYFHJCoKUE'\n",
    "!unzip flickr8k.zip\n",
    "!mv /content/flickr8k/Images /content/Image-Captioning/data\n",
    "!mv /content/flickr8k/captions.txt /content/Image-Captioning/data\n",
    "!rm -rf flickr8k\n",
    "!rm -rf flickr8k.zip\n",
    "!rm -rf sample_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torchsummary import summary\n",
    "\n",
    "from src.dataset import Flickr8k, vocab\n",
    "from src.models import Model\n",
    "from src.utils import show_imgs, DiscordNotifier\n",
    "from src.train import train_fit, validation_fit\n",
    "\n",
    "discord_notifier = DiscordNotifier('https://discord.com/api/webhooks/817689482844307476/bnBdXd3K-1Hoxx51ytzdd2r9NRvwt6AzR8DxuzGVskuqGx_ugaUQ1Lrb-EVp7y4Wu4Dj')\n",
    "print(\"Connected to GPU : \", torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(params, show_imgs=False, resume_training=False):\n",
    "    \n",
    "    # Set random seeds and deterministic pytorch for reproducibility\n",
    "    torch.manual_seed(params['seed'])       # pytorch random seed\n",
    "    np.random.seed(params['seed'])          # numpy random seed\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.enabled = False\n",
    "\n",
    "    captions_csv = pd.read_csv(os.path.abspath(params['csv_filepath']))\n",
    "\n",
    "    # split the dataframe into train and testget_word_embedding\n",
    "    train, val = train_test_split(captions_csv, test_size=0.2, random_state=params['seed'])\n",
    "    # split the test set into test and validation\n",
    "    val, test = train_test_split(val, test_size=0.1, random_state=params['seed'])\n",
    "\n",
    "    train = train.iloc[:160]\n",
    "    val   = val.iloc[:40]\n",
    "\n",
    "    my_transforms_train = transforms.Compose([\n",
    "                                                #transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "                                                transforms.Resize((params['IMG_SIZE'], params['IMG_SIZE'])),\n",
    "                                                transforms.ToTensor()\n",
    "    ])\n",
    "\n",
    "    my_transforms_val = transforms.Compose([\n",
    "                                                #transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "                                                transforms.Resize((params['IMG_SIZE'], params['IMG_SIZE'])),\n",
    "                                                transforms.ToTensor()\n",
    "    ])\n",
    "\n",
    "    train_set = Flickr8k(df=train, data_dir=os.path.abspath('data'), transforms=my_transforms_train)\n",
    "    train_dataloader = DataLoader(train_set, batch_size=params['batch_size'], shuffle=True, num_workers=params['num_workers'])\n",
    "\n",
    "    val_set = Flickr8k(df=val, data_dir=os.path.abspath('data'), transforms=my_transforms_val)\n",
    "    val_dataloader = DataLoader(val_set, batch_size=params['batch_size'], shuffle=True, num_workers=params['num_workers'])\n",
    "\n",
    "    if show_imgs:\n",
    "        for i_batch, sample_batched in enumerate(train_dataloader):\n",
    "            print(i_batch, sample_batched['image'].size(), sample_batched['caption'].size())\n",
    "            # observe 4th batch and stop.\n",
    "            if i_batch == 2:\n",
    "                for idx, caption_set in enumerate(sample_batched['caption']):\n",
    "                    for caption in caption_set:\n",
    "                        for token in caption.tolist():\n",
    "                            print(token, end=\" \")\n",
    "                            #print(vocab.get_word_token(token), end=\" \")\n",
    "                        print()\n",
    "                    show_imgs(sample_batched['image'][idx])\n",
    "                break\n",
    "\n",
    "    model = Model(\n",
    "            backbone=params['backbone'],\n",
    "            freeze_layers=params['freeze_layers'],\n",
    "            embed_size=128, \n",
    "            hidden_size=128, \n",
    "            vocab_size=vocab.MAX_INDEX, \n",
    "            lstm_cells=128, \n",
    "            lstm_dropout=0.5,\n",
    "            verbose=False,\n",
    "            device=params['device'])\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=params['lr'], betas=params['betas'], eps=params['eps'], weight_decay=params['weight_decay'])\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    train_loss , train_accuracy = [], []\n",
    "    val_loss , val_accuracy = [], []\n",
    "    start_epoch = 0\n",
    "\n",
    "    if resume_training:\n",
    "        loaded_checkpoint = torch.load(params['LOAD_CKPT_PATH'])\n",
    "\n",
    "        model.load_state_dict(loaded_checkpoint['state_dict'])\n",
    "        optimizer.load_state_dict(loaded_checkpoint['optimizer'])\n",
    "\n",
    "        start_epoch = loaded_checkpoint['epoch']\n",
    "\n",
    "        train_loss = loaded_checkpoint['training_loss']\n",
    "        train_accuracy = loaded_checkpoint['training_acc']\n",
    "\n",
    "        val_loss = loaded_checkpoint['val_loss']\n",
    "        val_accuracy = loaded_checkpoint['val_acc']\n",
    "\n",
    "    for epoch in range(start_epoch, params['epochs']):\n",
    "        print(f\"\\nEpoch {epoch+1} of {params['epochs']}\")\n",
    "        print(\"-\"*15)\n",
    "        print()\n",
    "\n",
    "        train_epoch_loss, train_epoch_accuracy = train_fit(params['device'], model, train_dataloader, optimizer, criterion, train_set)\n",
    "        val_epoch_loss, val_epoch_accuracy     = validation_fit(params['device'], model, val_dataloader, optimizer, criterion, val_set)\n",
    "\n",
    "        train_loss.append(train_epoch_loss)\n",
    "        train_accuracy.append(train_epoch_accuracy)\n",
    "\n",
    "        val_loss.append(val_epoch_loss)\n",
    "        val_accuracy.append(val_epoch_accuracy)\n",
    "\n",
    "        print(f\"Train Loss:\\t {train_epoch_loss:.8f}, Train Acc:\\t {train_epoch_accuracy:.8f}\")\n",
    "        print(f'Val Loss:\\t {val_epoch_loss:.8f}, Val Acc:\\t {val_epoch_accuracy:.8f}')\n",
    "\n",
    "        # save model checkpoint\n",
    "        checkpoint = {\n",
    "            'epoch'         : epoch + 1,\n",
    "            'state_dict'    : model.state_dict(),\n",
    "            'optimizer'     : optimizer.state_dict(),\n",
    "            'training_loss' : train_loss,\n",
    "            'training_acc'  : train_accuracy,\n",
    "            'val_loss'      : val_loss,\n",
    "            'val_acc'       : val_accuracy,\n",
    "        }\n",
    "        print(train_loss)\n",
    "        print(val_loss)\n",
    "\n",
    "        # Discord Notifier\n",
    "        discord_notifier.send_message(training_loss = train_epoch_loss, \n",
    "                       training_acc  = train_epoch_accuracy, \n",
    "                       val_loss      = val_epoch_loss, \n",
    "                       val_acc       = val_epoch_accuracy, \n",
    "                       epoch         = epoch+1, \n",
    "                       total_epochs  = params['epochs'], \n",
    "                       name          = \"Vgg16[Pretrained]-Lstm\", \n",
    "                       save_path     = params['CKPT_NAME'])\n",
    "\n",
    "        torch.save(checkpoint, os.path.join(os.path.abspath(params['CKPT_DIR']), params['CKPT_NAME']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    params = {\n",
    "        'csv_filepath'  : 'data/captions.csv',\n",
    "        'CKPT_DIR'      : '../drive/MyDrive/Projects/Image Captioning/models/',\n",
    "        'CKPT_NAME'     : 'resnet18-lstm.pt',\n",
    "        'LOAD_CKPT_PATH': '',\n",
    "        'seed'          : 42,\n",
    "        'device'        : 'cuda' if torch.cuda.is_available() else 'cpu',\n",
    "        'epochs'        : 3,\n",
    "        'lr'            : 0.001,\n",
    "        'betas'         : (0.9, 0.999),\n",
    "        'eps'           : 1e-8,\n",
    "        'weight_decay'  : 0.0005,\n",
    "        'num_workers'   : 4,  # simple rule 4*no.of gpu'\n",
    "        'IMG_SIZE'      : 224,\n",
    "        'batch_size'    : 128,\n",
    "        'backbone'      : 'vgg16',\n",
    "        'freeze_layers' : False\n",
    "    }\n",
    "\n",
    "    pprint(params)\n",
    "\n",
    "    main(\n",
    "        params=params,\n",
    "        show_imgs=False,\n",
    "        resume_training=False\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('image-captioning': conda)",
   "metadata": {
    "interpreter": {
     "hash": "4eeba685eeaeca2b7690177a14201459c1bc7b9dd9191f2682df96905cb14256"
    }
   },
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}